{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14241,"databundleVersionId":862020,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch==0.3.0 albumentations==1.3.0\n\n# 1) Imports and basic config\nimport os, gc, random, math\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport numpy as np, pandas as pd, cv2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport segmentation_models_pytorch as smp\n\n# Paths\nDATA_DIR = Path(\"/kaggle/input/severstal-steel-defect-detection\")\nTRAIN_CSV = DATA_DIR / \"train.csv\"\nIMG_DIR = DATA_DIR / \"train_images\"\nWORK_DIR = Path(\"/kaggle/working\")\nWORK_DIR.mkdir(exist_ok=True)\n\n# Constants\nH, W = 256, 1600\nNUM_CLASSES = 4\nBATCH_SIZE = 2 # set 2 (if OOM -> 1); if you have more mem, increase\nEPOCHS = 30\nLR = 1e-4\nSEED = 42\nNUM_WORKERS = 4\nUSE_AMP = True # mixed precision\n\n# Repro\ndef seed_everything(seed=SEED):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nseed_everything()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:29:52.338796Z","iopub.execute_input":"2025-08-07T23:29:52.339121Z","iopub.status.idle":"2025-08-07T23:29:55.623678Z","shell.execute_reply.started":"2025-08-07T23:29:52.339093Z","shell.execute_reply":"2025-08-07T23:29:55.622871Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"\n# 2) RLE decode and helper\ndef rle_decode(mask_rle, shape=(256,1600)):\n    if not isinstance(mask_rle, str) or mask_rle == '':\n        return np.zeros(shape, dtype=np.uint8)\n    s = np.array(mask_rle.split(), dtype=int)\n    starts, lengths = s[0::2] - 1, s[1::2]\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:30:06.785859Z","iopub.execute_input":"2025-08-07T23:30:06.786156Z","iopub.status.idle":"2025-08-07T23:30:06.791716Z","shell.execute_reply.started":"2025-08-07T23:30:06.786131Z","shell.execute_reply":"2025-08-07T23:30:06.790934Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"\n# 3) Build memmap masks (one-time)\ndf = pd.read_csv(TRAIN_CSV)\nimage_ids = df['ImageId'].unique()\nN = len(image_ids)\nMASK_MEMMAP = WORK_DIR / \"masks_memmap.npy\"\nIDS_PATH = WORK_DIR / \"image_ids.npy\"\n\nif not MASK_MEMMAP.exists() or not IDS_PATH.exists():\n    print(\"Building mask memmap... (takes a few minutes)\")\n    memmap = np.memmap(str(MASK_MEMMAP), dtype=np.uint8, mode='w+', shape=(N, H, W, NUM_CLASSES))\n    ids = []\n    for i, img_id in enumerate(tqdm(image_ids)):\n        ids.append(img_id)\n        df_img = df[df['ImageId'] == img_id]\n        for c in range(1, NUM_CLASSES+1):\n            rle = df_img[df_img['ClassId'] == c]['EncodedPixels']\n            rle = rle.values[0] if len(rle) > 0 else ''\n            mask = rle_decode(rle, shape=(256,1600)).astype(np.uint8)\n            memmap[i,:,:,c-1] = mask\n    memmap.flush()\n    del memmap\n    np.save(str(IDS_PATH), np.array(ids))\n    print(\"Saved memmap and ids\")\nelse:\n    print(\"Memmap exists, skipping build\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:30:32.259649Z","iopub.execute_input":"2025-08-07T23:30:32.260353Z","iopub.status.idle":"2025-08-07T23:30:32.475588Z","shell.execute_reply.started":"2025-08-07T23:30:32.260328Z","shell.execute_reply":"2025-08-07T23:30:32.474799Z"}},"outputs":[{"name":"stdout","text":"Memmap exists, skipping build\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"\n# 4) Dataset + transforms\ntrain_transform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.OneOf([A.RandomBrightnessContrast(), A.CLAHE()], p=0.6),\n    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.05, rotate_limit=10, p=0.6),\n    A.OneOf([A.GaussNoise(), A.Blur(blur_limit=3)], p=0.3),\n    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n    ToTensorV2()\n])\n\nvalid_transform = A.Compose([\n    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n    ToTensorV2()\n])\n\nclass SeverstalDataset(Dataset):\n    def __init__(self, ids, img_dir, memmap_path, transforms=None):\n        self.ids = ids\n        self.img_dir = str(img_dir)\n        self.transforms = transforms\n        # open memmap read-only\n        self.masks = np.memmap(str(memmap_path), dtype=np.uint8, mode='r', shape=(len(np.load(str(IDS_PATH))), H, W, NUM_CLASSES))\n        # We assume ids are subset of IDS_PATH order - we will map idx -> global index\n        self.global_ids = np.load(str(IDS_PATH)).tolist()\n        self.index_map = {img: i for i, img in enumerate(self.global_ids)}\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        img_id = self.ids[idx]\n        # load image\n        img_path = os.path.join(self.img_dir, img_id)\n        img = cv2.imread(img_path)\n        if img is None:\n            raise FileNotFoundError(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        # load mask from memmap using global index\n        gidx = self.index_map[img_id]\n        mask = self.masks[gidx] # (H,W,4), uint8\n        mask = mask.astype('float32')\n        if self.transforms:\n            augmented = self.transforms(image=img, mask=mask)\n            img = augmented['image'] # tensor C,H,W\n            mask = augmented['mask'] # tensor H,W,4 -> ToTensorV2 gives C,H,W? Albumentations ToTensorV2 returns tensor HWC->CHW for image, mask is converted similarly as ndarray\n            # ensure mask shape is (C,H,W)\n            if isinstance(mask, torch.Tensor):\n                # sometimes mask is HWC tensor, convert to CHW\n                if mask.ndim == 3 and mask.shape[0] != NUM_CLASSES:\n                    mask = mask.permute(2,0,1)\n        else:\n            img = torch.from_numpy(img.transpose(2,0,1)).float().div(255.0)\n            mask = torch.from_numpy(mask.transpose(2,0,1)).float()\n        return img, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:31:06.237120Z","iopub.execute_input":"2025-08-07T23:31:06.237424Z","iopub.status.idle":"2025-08-07T23:31:06.253663Z","shell.execute_reply.started":"2025-08-07T23:31:06.237401Z","shell.execute_reply":"2025-08-07T23:31:06.252846Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"\n# 5) Train/val split and dataloaders\nall_ids = np.load(str(IDS_PATH)).tolist()\nfrom sklearn.model_selection import train_test_split\ntrain_ids, val_ids = train_test_split(all_ids, test_size=0.1, random_state=SEED)\n\ntrain_ds = SeverstalDataset(train_ids, IMG_DIR, MASK_MEMMAP, transforms=train_transform)\nval_ds = SeverstalDataset(val_ids, IMG_DIR, MASK_MEMMAP, transforms=valid_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\nprint(\"Train:\", len(train_ds), \"Val:\", len(val_ds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:31:22.582513Z","iopub.execute_input":"2025-08-07T23:31:22.582830Z","iopub.status.idle":"2025-08-07T23:31:22.598336Z","shell.execute_reply.started":"2025-08-07T23:31:22.582808Z","shell.execute_reply":"2025-08-07T23:31:22.597621Z"}},"outputs":[{"name":"stdout","text":"Train: 5999 Val: 667\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"\n# 6) Model — segmentation_models_pytorch Unet with resnet34\nENCODER = \"resnet34\"\nENCODER_WEIGHTS = \"imagenet\"\nmodel = smp.Unet(\n    encoder_name=ENCODER,\n    encoder_weights=ENCODER_WEIGHTS,\n    in_channels=3,\n    classes=NUM_CLASSES,\n    activation=None, # we will use BCEWithLogits\n)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:31:48.842183Z","iopub.execute_input":"2025-08-07T23:31:48.842960Z","iopub.status.idle":"2025-08-07T23:31:49.850571Z","shell.execute_reply.started":"2025-08-07T23:31:48.842931Z","shell.execute_reply":"2025-08-07T23:31:49.849797Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 285MB/s]\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"\n# 7) Losses, metrics\nbce_loss = nn.BCEWithLogitsLoss()\n\ndef dice_loss_logits(logits, targets, eps=1e-6):\n    probs = torch.sigmoid(logits)\n    num = 2.0 * (probs * targets).sum(dim=(2,3))\n    den = probs.sum(dim=(2,3)) + targets.sum(dim=(2,3))\n    dice = (num + eps) / (den + eps)\n    return 1.0 - dice.mean()\n\ndef combined_loss(logits, targets, bce_w=0.5):\n    b = bce_loss(logits, targets)\n    d = dice_loss_logits(logits, targets)\n    return b * bce_w + d * (1.0 - bce_w)\n\ndef mean_dice_metric(logits, targets, thr=0.5):\n    with torch.no_grad():\n        probs = torch.sigmoid(logits)\n        preds = (probs > thr).float()\n        num = 2.0 * (preds * targets).sum(dim=(2,3))\n        den = preds.sum(dim=(2,3)) + targets.sum(dim=(2,3))\n        dice = (num + 1e-6) / (den + 1e-6)\n        return dice.mean().item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:32:14.116292Z","iopub.execute_input":"2025-08-07T23:32:14.116591Z","iopub.status.idle":"2025-08-07T23:32:14.124953Z","shell.execute_reply.started":"2025-08-07T23:32:14.116560Z","shell.execute_reply":"2025-08-07T23:32:14.124128Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"\n\n# 8) Optimizer, scheduler, amp scaler\noptimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\nscaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:32:30.206925Z","iopub.execute_input":"2025-08-07T23:32:30.207214Z","iopub.status.idle":"2025-08-07T23:32:30.214037Z","shell.execute_reply.started":"2025-08-07T23:32:30.207191Z","shell.execute_reply":"2025-08-07T23:32:30.213207Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n/tmp/ipykernel_36/1209872849.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"\n# 9) Training / validation loops\ndef train_one_epoch(model, loader, optimizer, device, scaler):\n    model.train()\n    running_loss = 0.0\n    num_samples = 0\n    pbar = tqdm(loader, desc=\"Train\", leave=False)\n    for imgs, masks in pbar:\n        imgs = imgs.to(device, dtype=torch.float32, non_blocking=True)\n        masks = masks.to(device, dtype=torch.float32, non_blocking=True)\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast(enabled=USE_AMP):\n            logits = model(imgs)\n            loss = combined_loss(logits, masks)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        running_loss += loss.item() * imgs.size(0)\n        num_samples += imgs.size(0)\n        pbar.set_postfix({'loss': running_loss / num_samples})\n    return running_loss / num_samples\n\ndef validate(model, loader, device):\n    model.eval()\n    running_loss = 0.0\n    num = 0\n    dice_sum = 0.0\n    pbar = tqdm(loader, desc=\"Val\", leave=False)\n    with torch.no_grad():\n        for imgs, masks in pbar:\n            imgs = imgs.to(device, dtype=torch.float32, non_blocking=True)\n            masks = masks.to(device, dtype=torch.float32, non_blocking=True)\n            logits = model(imgs)\n            loss = combined_loss(logits, masks)\n            running_loss += loss.item() * imgs.size(0)\n            dice_sum += mean_dice_metric(logits, masks)\n            num += imgs.size(0)\n            pbar.set_postfix({'v_loss': running_loss / num, 'v_dice': dice_sum / num})\n    return running_loss / max(1, num), dice_sum / max(1, num)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:33:34.053436Z","iopub.execute_input":"2025-08-07T23:33:34.053729Z","iopub.status.idle":"2025-08-07T23:33:34.061762Z","shell.execute_reply.started":"2025-08-07T23:33:34.053707Z","shell.execute_reply":"2025-08-07T23:33:34.061040Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"\n# 10) Run training with checkpointing\nbest_dice = 0.0\nbest_path = WORK_DIR / \"best_model.pth\"\n\nfor epoch in range(1, EPOCHS+1):\n    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n    train_loss = train_one_epoch(model, train_loader, optimizer, device, scaler)\n    val_loss, val_dice = validate(model, val_loader, device)\n    scheduler.step(val_dice)\n    print(f\"Train loss: {train_loss:.5f} | Val loss: {val_loss:.5f} | Val mean Dice: {val_dice:.5f}\")\n    if val_dice > best_dice:\n        best_dice = val_dice\n        torch.save({'model_state_dict': model.state_dict(), 'epoch': epoch, 'val_dice': val_dice}, str(best_path))\n        print(f\"Saved best model: {best_path} (Dice {val_dice:.5f})\")\n    # free mem\n    gc.collect()\n    torch.cuda.empty_cache()\n\nprint(\"Training complete. Best val dice:\", best_dice)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T23:33:50.793156Z","iopub.execute_input":"2025-08-07T23:33:50.793433Z","iopub.status.idle":"2025-08-08T02:27:10.540527Z","shell.execute_reply.started":"2025-08-07T23:33:50.793411Z","shell.execute_reply":"2025-08-08T02:27:10.539569Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"Train:   0%|          | 0/3000 [00:00<?, ?it/s]/tmp/ipykernel_36/1586846829.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=USE_AMP):\n                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.50481 | Val loss: 0.44589 | Val mean Dice: 0.49701\nSaved best model: /kaggle/working/best_model.pth (Dice 0.49701)\n\nEpoch 2/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.45052 | Val loss: 0.43776 | Val mean Dice: 0.69832\nSaved best model: /kaggle/working/best_model.pth (Dice 0.69832)\n\nEpoch 3/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.44413 | Val loss: 0.43649 | Val mean Dice: 0.66999\n\nEpoch 4/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.44012 | Val loss: 0.43679 | Val mean Dice: 0.73069\nSaved best model: /kaggle/working/best_model.pth (Dice 0.73069)\n\nEpoch 5/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.43755 | Val loss: 0.43411 | Val mean Dice: 0.62649\n\nEpoch 6/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.43557 | Val loss: 0.43559 | Val mean Dice: 0.49872\n\nEpoch 7/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.43361 | Val loss: 0.42827 | Val mean Dice: 0.51838\n\nEpoch 8/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.43226 | Val loss: 0.42702 | Val mean Dice: 0.53546\n\nEpoch 9/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42769 | Val loss: 0.42379 | Val mean Dice: 0.69867\n\nEpoch 10/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42641 | Val loss: 0.42321 | Val mean Dice: 0.65352\n\nEpoch 11/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42546 | Val loss: 0.42666 | Val mean Dice: 0.72157\n\nEpoch 12/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42426 | Val loss: 0.42510 | Val mean Dice: 0.55937\n\nEpoch 13/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42216 | Val loss: 0.42162 | Val mean Dice: 0.75660\nSaved best model: /kaggle/working/best_model.pth (Dice 0.75660)\n\nEpoch 14/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42117 | Val loss: 0.42268 | Val mean Dice: 0.74305\n\nEpoch 15/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42085 | Val loss: 0.42286 | Val mean Dice: 0.72271\n\nEpoch 16/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.42002 | Val loss: 0.42452 | Val mean Dice: 0.70005\n\nEpoch 17/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41990 | Val loss: 0.42541 | Val mean Dice: 0.69392\n\nEpoch 18/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41854 | Val loss: 0.42494 | Val mean Dice: 0.72863\n\nEpoch 19/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41815 | Val loss: 0.42202 | Val mean Dice: 0.76565\nSaved best model: /kaggle/working/best_model.pth (Dice 0.76565)\n\nEpoch 20/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41759 | Val loss: 0.42194 | Val mean Dice: 0.74083\n\nEpoch 21/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41695 | Val loss: 0.42150 | Val mean Dice: 0.77048\nSaved best model: /kaggle/working/best_model.pth (Dice 0.77048)\n\nEpoch 22/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41714 | Val loss: 0.41867 | Val mean Dice: 0.72212\n\nEpoch 23/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41677 | Val loss: 0.42588 | Val mean Dice: 0.69315\n\nEpoch 24/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41678 | Val loss: 0.42115 | Val mean Dice: 0.75965\n\nEpoch 25/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41637 | Val loss: 0.42446 | Val mean Dice: 0.64389\n\nEpoch 26/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41579 | Val loss: 0.42172 | Val mean Dice: 0.75841\n\nEpoch 27/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41559 | Val loss: 0.41991 | Val mean Dice: 0.78175\nSaved best model: /kaggle/working/best_model.pth (Dice 0.78175)\n\nEpoch 28/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41540 | Val loss: 0.42650 | Val mean Dice: 0.74966\n\nEpoch 29/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41455 | Val loss: 0.42006 | Val mean Dice: 0.77842\n\nEpoch 30/30\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.41499 | Val loss: 0.42097 | Val mean Dice: 0.76330\nTraining complete. Best val dice: 0.7817511032859067\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"\n# 11) Postprocessing + RLE export (inference on test images, if you have test set)\n# Example post-process function used on Segformer code earlier\ndef mask_to_rle(img):\n    # img: 2D numpy array (H, W) of binary mask\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef post_process(probability, threshold=0.5, min_size=3500):\n    mask = (probability > threshold).astype(np.uint8)\n    num_component, component = cv2.connectedComponents(mask)\n    predictions = np.zeros_like(mask, dtype=np.uint8)\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n    return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T02:32:56.769287Z","iopub.execute_input":"2025-08-08T02:32:56.770016Z","iopub.status.idle":"2025-08-08T02:32:56.775375Z","shell.execute_reply.started":"2025-08-08T02:32:56.769993Z","shell.execute_reply":"2025-08-08T02:32:56.774767Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# PREDICTIONS\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\n# ==== SETTINGS ====\nTEST_DIR = \"/kaggle/input/severstal-steel-defect-detection/test_images\"  # change if needed\nIMG_HEIGHT, IMG_WIDTH = 256, 1600  # match your training size\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ==== RLE ENCODING ====\ndef rle_encode(mask):\n    pixels = mask.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(str(x) for x in runs)\n\n# ==== PREDICTION LOOP ====\nsubmission = []\nmodel.eval()\n\ntest_image_names = sorted(os.listdir(TEST_DIR))  # get all test image filenames\n\nwith torch.no_grad():\n    for img_name in tqdm(test_image_names):\n        img_path = os.path.join(TEST_DIR, img_name)\n\n        # Read & preprocess image\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n        image = torch.tensor(image / 255.0, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n\n        # Predict\n        pred = model(image)\n        pred = torch.sigmoid(pred).cpu().numpy()[0]\n\n        # Loop over 4 defect classes\n        for cls in range(4):\n            mask = pred[cls]\n            mask = (mask > 0.5).astype(np.uint8)  # binary threshold\n\n            if mask.sum() == 0:\n                submission.append([f\"{img_name}_{cls+1}\", \"\"])\n            else:\n                rle = rle_encode(mask)\n                submission.append([f\"{img_name}_{cls+1}\", rle])\n\n# ==== SAVE CSV ====\ndf = pd.DataFrame(submission, columns=[\"ImageId_ClassId\", \"EncodedPixels\"])\ndf.to_csv(\"submission.csv\", index=False)\n\nprint(\"✅ submission.csv created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T02:51:56.238731Z","iopub.execute_input":"2025-08-08T02:51:56.239056Z","iopub.status.idle":"2025-08-08T02:56:31.227328Z","shell.execute_reply.started":"2025-08-08T02:51:56.239033Z","shell.execute_reply":"2025-08-08T02:56:31.226484Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 5506/5506 [04:34<00:00, 20.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ submission.csv created successfully!\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}